{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-23T14:50:56.285834Z",
     "start_time": "2024-11-23T14:50:54.726253Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "splits = {'train': 'data/train-00000-of-00001.parquet', 'test': 'data/test-00000-of-00001.parquet'}\n",
    "df = pd.read_parquet(\"hf://datasets/mlabonne/llmtwin/\" + splits[\"train\"])\n",
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                         instruction  \\\n",
       "0  Explain how list comprehensions improve iterat...   \n",
       "1        Define what an LLM Twin is and its purpose.   \n",
       "2  Describe how audio narrations can enhance the ...   \n",
       "3  Describe the role of a vector database in embe...   \n",
       "4  Explain the concept of quantization in the con...   \n",
       "\n",
       "                                              output  \n",
       "0  List comprehensions serve as a highly efficien...  \n",
       "1  An LLM Twin is an AI-driven character designed...  \n",
       "2  Audio narrations can significantly enhance the...  \n",
       "3  A vector database serves as a crucial reposito...  \n",
       "4  Quantization in the context of LLMs refers to ...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explain how list comprehensions improve iterat...</td>\n",
       "      <td>List comprehensions serve as a highly efficien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Define what an LLM Twin is and its purpose.</td>\n",
       "      <td>An LLM Twin is an AI-driven character designed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Describe how audio narrations can enhance the ...</td>\n",
       "      <td>Audio narrations can significantly enhance the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Describe the role of a vector database in embe...</td>\n",
       "      <td>A vector database serves as a crucial reposito...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Explain the concept of quantization in the con...</td>\n",
       "      <td>Quantization in the context of LLMs refers to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T14:56:59.816570Z",
     "start_time": "2024-11-23T14:50:56.315905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"mlabonne/TwinLlama-3.1-8B\")"
   ],
   "id": "8b090d51014e6366",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8309c86462324d2c84c878d2ed38d8b4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00001-of-00004.safetensors:  41%|####1     | 2.06G/4.98G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "466a2f3ac72447a7927f35b7d192e774"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "affa64009b2e4055837cb7603475cf18"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e76937e786c242429c9cbc40689b410f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "05831fba0e964692b2ff3598cccff3b4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e436447d93543689f8db9c8a2ef9f44"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-11-23T15:01:21.164072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the prompt\n",
    "prompt = \"What is the capital of France?\"\n",
    "\n",
    "# Generate a response\n",
    "response = pipe(prompt, max_length=50, num_return_sequences=1, truncation=True)\n",
    "\n",
    "# Print the response\n",
    "print(response[0]['generated_text'])"
   ],
   "id": "5b546e6271689518",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8590d38a6eab24af"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
